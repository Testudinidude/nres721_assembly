---
title: "RADseq data assembly in `ipyrad`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
author: "Todd W. Pierson"
date: "16 October 2019"
---
<style>
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width = 200, height = 50)
#```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, width.cutoff=120)
```

```{r, include=FALSE}
setwd("/Volumes/G-DRIVE/Dropbox/Teaching/2019_NRES_721/nres721_assembly")
```

<div class="alert alert-danger">
  <strong>Note:</strong> This tutorial is written to be a basic introduction to assembling RADseq-style data in [`ipyrad`](https://ipyrad.readthedocs.io/) for an in-class demonstration in UNR's NRES 721, not to be a comprehensive guide to doing this for research purposes. 
  
**Students: if you wish to follow along, please install the latest version of `ipyrad` (follow the `conda` directions [here](https://ipyrad.readthedocs.io/en/latest/3-installation.html)); I have written this tutorial using `v0.9.14`**. This program is written for Linux or Mac operating systems; if you are running Windows, you can try to run `ipyrad` through your favorite emulator or virtual machine, or you can just follow along as we move through the tutorial. We'll return to `R` for downstream analyses! 
</div>

## Introduction 

Reduced-representation genomic sequencing (e.g., RADseq) is a popular group of methods for generating large-scale datasets for population genomic and phylogenomic studies, especially for non-model organisms without reference genomes. The sequencing reads generated from these methods come from thousands to millions of different portions of the genome, and there are numerous methods for "assembling" these data. Typically, this means clustering sequences (either *de novo* or against a reference genome), aligning sequences, and callling SNPs.

In this tutorial, we'll practice assembling RADseq-style data. Our objectives are to:

1) understand the general concepts re: how `ipyrad` assembles data
2) compare results from a *de novo* and reference-based assembly
3) produce output files for use in downstream analyses

To do this, we'll use data from the patch-nosed salamander (*Urspelerpes brucei*). This is a tiny (~25 mm) lungless salamander endemic to just ~ 20 km^2^ in Georgia and South Carolina. Aren't they beautiful? 

<center>![](https://live.staticflickr.com/277/19325478625_f58f9b7b15_b.jpg){ width=40% }</center>

\

Let's jump right in and start assembling data. If you haven't already, navigate to a local directory you'd like to work from:

```{bash, comment = NA, eval = FALSE}
cd [your working directory]
```

Next, we want to download the data we'll use. If you're in your working directory, the following command will download our data into a `\data` directory within it:

```{bash, eval = FALSE}
svn checkout https://github.com/twpierson/nres721_assembly/trunk/data
```

These data are a small subset of a larger, unpublished RADcap [(Hoffberg et al. 2016)](https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.12566) dataset generated from individuals sampled across the small distribution of this *Urspelerpes*. This subset contains data from twelve individuals: three each from four collection localities. We can see these files in our `\data` directory:

```{bash, comment=NA}
ls ./data/*
```

There are a total of 24 files, consisting of a R1 and R2 file for each of the nine samples. Samples U03--U05 come from one collection locality, U19--U21 from a second, U23--U25 from a third, and U41--U43 from a fourth. These data have already been demultiplexed and "decloned" (i.e., PCR duplicates removed); the data for each sample has been subsetted down to 37,500 reads for consistently and manageability in this tutorial. 

## *De novo* assembly
<div class="alert alert-danger">
  <strong>Note:</strong> Today, we are going to use `ipyrad` to "call" genotypes. Some studies (e.g., [Gompert and Buerkle 2011](https://www.genetics.org/content/187/3/903?ijkey=db1c78ecc5d6122e25f7ddb64c0447c2fa3d6b32&keytype2=tf_ipsecsha); [Fumagalli et al. 2013](https://www.genetics.org/content/195/3/979)) have demonstrated the pitfalls of definitive genotype calling and instead strongly encourage the use of "genotype likelihoods", which allow error in estimating genotypes to propogate through downstream analyses. For the sake of simplicity today, we will be calling (and later, using) called genotypes.
</div>

There are two general ways in which we can assemble these data in `ipyrad`: *de *novo and using a reference genome. In a *de novo* assembly, reads are clustered and aligned against other reads, and no reference genome is required. This is really great for non-model organisms for which reference genomes don't exist! For example, in our case, there does not exist a full reference genome for any close relative of *Urspelerpes*; in fact, because salamanders have very large genomes, only one chromosome-level genome assembly exists ([the 32 Gb axolotl genome](https://genome.cshlp.org/content/29/2/317.long)). For our purposes today, we're going to start by assembling these data *de novo* ([but see the final tutorial for an example using an assembled reference genome!](https://twpierson.github.io/nres721_genome/)).

<div class="alert alert-info">
  <strong>Discussion:</strong> What might the advantages be of assembling against a reference genome?
</div>

From within our working directory, we'll initiate a new assembly called `ubrucei_denovo` (and thus, create a parameters file) by entering:

```{bash, eval = FALSE}
ipyrad -n ubrucei_denovo
```

Let's now look at this template of an `ipyrad` parameters file:

```{bash comment=NA, eval = FALSE}
cat params-ubrucei_denovo.txt
```

```{bash comment=NA, echo = FALSE, }
cat ipyrad_files/params-template.txt
```

This is the file in which you can tweak a number of assembly parameters. See [here](https://ipyrad.readthedocs.io/parameters.html) for a thorough description of what each of these means. For our purposes, we only need to change a few. In your favorite text editor, open `params-ubrucei_denovo.txt` and change the following lines:

* `[4] [sorted_fastq_path]` : change this parameter to `data/*fq.gz`
* `[7] [datatype]` : change this parameter to `pair3rad`
* `[8] [restriction_overhang]` : change this parameter to `CTAGAT,AATTC,CTAGC`
* `[16] [filter_adapters]` : change this parameter to `2`
* `[21] [min_samples_locus]` : change this parameter to `5`
* `[25] [trim_reads]` : change this parameter to `10, 120, 10, 120` ; We're trimming off the first ten bases to deal with mapping issues caused by the inclusion/exclusion of restriction sites and trimming to a maximum length of 120 to normalize read length. This is relatively project-specific and not something you need to worry too much about when trying to understand these general concepts!
* `[27] [output_formats]` : change this parameter to `*`

Then, save the file with these updates. Next, we'll assemble the data. This whole process isn't too computationally-intensive (i.e., it took ~40 minutes on my 16 GB RAM, 4-core Macbook), but we might not want to wait quite that long. Don't worry—there is an opportunity to assemble data in real-time later in this tutorial. Below, we'll break this down step-by-step. **Students in class: don't actually run any of these commands until we get to the ["Reference-based assembly"](#refassembly) section.**

### steps 1 & 2
We'll do this first assembly step-by-step and talk about the output. First, we'll run step 1. **Note: the `-c 2` argument tells my computer to run this using two cores. You can adjust this as necsesary depending upon what resources you have available. By default, `ipyrad` will use all cores available.**

```{bash eval = FALSE}
ipyrad -p params-ubrucei_denovo.txt -s 1 -c 2
```

This step simply reads in our data files, and we can review the results in the `ubrucei_denovo_s1_demultiplex_stats.txt` file.

```{bash eval = FALSE, echo = TRUE, comment = NA}
cat ubrucei_denovo_s1_demultiplex_stats.txt
```

```{bash eval = TRUE, echo = FALSE, comment = NA}
cat ipyrad_files/ubrucei_denovo_s1_demultiplex_stats.txt
```

Next, we'll run step 2.

```{bash eval = FALSE}
ipyrad -p params-ubrucei_denovo.txt -s 2
```

This step filters and edits reads, using thresholds set in the parameters file. This means that we (probably) don't need to filter data before entering `ipyrad`! We can view the results of this step in the `ubrucei_denovo_edits/s2_rawedit_stats.txt` file:

```{bash eval = FALSE, echo = TRUE, comment = NA}
cat ubrucei_denovo_edits/s2_rawedit_stats.txt
```

```{bash eval = TRUE, echo = FALSE, comment = NA}
cat ipyrad_files/ubrucei_denovo_edits/s2_rawedit_stats.txt
```

### step 3
Next, we'll run step 3. This is the within-sample clustering step, in which the reads are compared against each other, clustered based on similarity into "loci", and then aligned. This is a relatively computationally intensive step.

```{bash eval = FALSE}
ipyrad -p params-ubrucei_denovo.txt -s 3
```

Once completed, we can view the results of this step in the `ubrucei_denovo_clust_0.85/s3_cluster_stats.txt` file:

```{bash eval = FALSE, echo = TRUE, comment = NA}
cat ubrucei_denovo_clust_0.85/s3_cluster_stats.txt
```

```{bash eval = TRUE, echo = FALSE, comment = NA}
cat ipyrad_files/ubrucei_denovo_clust_0.85/s3_cluster_stats.txt
```

<div class="alert alert-info">
  <strong>Discussion:</strong> What can you glean from this output? What is the distribution of our sequencing coverage? What do you think might contribute to heterogeneity in sequencing coverage among and within samples?
</div>

### steps 4 & 5
Next, we'll run steps 4 and 5 together. These steps estimate sequencing error rates, estimate genome-wide heterozygosity, and call consensus sequences for each individual for use in across-sample clustering.

```{bash eval = FALSE}
ipyrad -p params-ubrucei_denovo.txt -s 45
```

### step 6
We'll skip over the results from steps 4 & 5 and proceed immediately to step 6. This is another "clustering" step, but instead of clustering reads within individuals, we're clustering loci across individuals. With many samples, this step can be computationally intensive, but it should run quite quickly for us.

```{bash eval = FALSE}
ipyrad -p params-ubrucei_denovo.txt -s 6
```

### step 7
Finally, we'll run step 7, in which loci are catalogued, and data are output into a variety of formats (e.g., VCF, PHYLIP, Structure, etc.) for downstream analysis. 

```{bash eval = FALSE}
ipyrad -p params-ubrucei_denovo.txt -s 7
```

This also produces a useful file (`ubrucei_denovo_outfiles/ubrucei_denovo_stats.txt`) with summary statistics, which looks like this:

```{bash eval = TRUE, echo = FALSE, comment = NA}
cat ipyrad_files/ubrucei_denovo_outfiles/ubrucei_denovo_stats.txt
```

<div class="alert alert-info">
  <strong>Discussion:</strong> Examine these summary statistics. At what steps are loci being filtered out? Is this indicative of any problems with our analysis or data?
</div>

## Reference-based assembly {#refassembly}
Although we don't want to use a full genome assembly as a reference genome, these RADcap data provide us with another opportunity for assembly: a "pseudo-reference" genome. To understand this, it's worth thinking a bit about what the RADcap data are. We created 3RAD libraries—each of which probably contained hundreds of thousands of loci—for each individual, but then we conducted a "sequence capture" reaction to enrich them for a pre-selected subset of 1000 loci. So ideally, these reads are mostly from those 1000 loci. Rather than assemble these *de novo*, if we have a "reference" sequence for each those 1000 loci, we can just assemble against those!

<div class="alert alert-info">
  <strong>Discussion:</strong> How might you predict that assembling against a pseudo-reference genome will change the results of our assembly?
</div>

I've prepared one such pseudo-reference, and we can download the `\reference` directory in which it's housed by entering the following command:

```{bash, eval = FALSE}
svn checkout https://github.com/twpierson/nres721_assembly/trunk/reference
```

We can peek at this pseudo-reference—formatted as a FASTA file—here:

```{bash, eval = TRUE, comment = NA}
head -n 10 reference/ubrucei_pseudoreference.fasta
```

<div class="alert alert-info">
  <strong>Discussion:</strong> How is this formatted? Where did R1 and R2 data end up, and what does this tell you about the size of the loci?
</div>

Now, let's assemble our data again—this time against this pseudo-reference! Since most of our parameters will stay the same, we can create a new parameters file here by copying our *de novo* parameters file.

```{bash, eval = FALSE}
cp params-ubrucei_denovo.txt params-ubrucei_reference.txt
```

We should then alter the following parameters:

* `[0] [assembly_name]` : change this parameter to `ubrucei_reference`
* `[5] [assembly_method]` : change this parameter to `reference`
* `[6] [reference_sequence]` : change this parameter to `reference/ubrucei_pseudoreference.fasta`

Now, we'll run this whole assembly, rather than break it down step-by-step like before. This should run relatively quickly, if you want to follow along.

```{bash, eval = FALSE}
ipyrad -p params-ubrucei_reference.txt -s 1234567
```

Once it finishes, let's look at the same summary statistics file. 

```{bash eval = FALSE, echo = TRUE, comment = NA}
cat ubrucei_reference_outfiles/ubrucei_reference_stats.txt
```

```{bash eval = TRUE, echo = FALSE, comment = NA}
cat ipyrad_files/ubrucei_reference_outfiles/ubrucei_reference_stats.txt
```

<div class="alert alert-info">
  <strong>Discussion:</strong> Compare and contrast these results to those from the *de novo* assembly. What can explain the differences? It might be worth reflecting back upon what exactly RADcap data are.
</div>

We've finished our assemblies! [Next week](https://twpierson.github.io/nres721_popgen_phylo/), we'll conduct some basic population genomic and phylogenomic analyses to see what we can learn from these data.